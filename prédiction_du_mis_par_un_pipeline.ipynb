{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLJIJfKWrq42WFiMyreD/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamgachristelle/SN-GROUPE-5/blob/main/pr%C3%A9diction_du_mis_par_un_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code de G√©n√©ration de Donn√©es"
      ],
      "metadata": {
        "id": "SQOLsAR4gkMm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-ZU5khBw-oW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# TITRE : D√©finition des param√®tres de taille et de taux d'√©chec pour le jeu de donn√©es.\n",
        "# --------------------------------------------------------------------------------------\n",
        "NB_LIGNES = 2057  # Nombre total de lignes (2000 + 57 erreurs suppl√©mentaires)\n",
        "NB_FAILURES_TARGET = 357 # Nous garantissons ce nombre exact d'√©checs (300 initial + 57)\n",
        "NB_SUCCESSES_TARGET = NB_LIGNES - NB_FAILURES_TARGET # 1700 r√©ussites\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# TITRE : G√©n√©ration des lignes simulant les ex√©cutions r√©ussies (83% du total).\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Donn√©es de SUCC√àS (Status = success)\n",
        "data_success = pd.DataFrame({\n",
        "    'status': ['success'] * NB_SUCCESSES_TARGET,\n",
        "    'code_lines_changed': np.random.randint(10, 800, size=NB_SUCCESSES_TARGET)\n",
        "})\n",
        "data_success['pred_risk_fail'] = np.random.uniform(0.01, 0.15, size=NB_SUCCESSES_TARGET)\n",
        "data_success['error_tag'] = 'None'\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# TITRE : G√©n√©ration des lignes simulant les √©checs (17% du total) pour enrichir l'analyse d'erreur.\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Donn√©es d'√âCHECS (Status = failure)\n",
        "data_failure = pd.DataFrame({\n",
        "    'status': ['failure'] * NB_FAILURES_TARGET,\n",
        "    'code_lines_changed': np.random.randint(50, 900, size=NB_FAILURES_TARGET) # Les √©checs peuvent avoir des changements plus grands\n",
        "})\n",
        "data_failure['pred_risk_fail'] = np.random.uniform(0.65, 0.95, size=NB_FAILURES_TARGET)\n",
        "# R√©partition des types d'erreurs\n",
        "data_failure['error_tag'] = np.random.choice(['TestFail', 'DependencyError', 'Timeout', 'AuthIssue'], size=NB_FAILURES_TARGET)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# TITRE : Consolidation des donn√©es Succ√®s/√âchec en un seul jeu de donn√©es m√©lang√©.\n",
        "# --------------------------------------------------------------------------------------\n",
        "# COMBINER et m√©langer les jeux de donn√©es\n",
        "data = pd.concat([data_success, data_failure]).reset_index(drop=True)\n",
        "np.random.shuffle(data.values)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# TITRE : Attribution d'un ID unique, d'un horodatage et des variables cat√©gorielles (branches, d√©p√¥ts).\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Ajout des colonnes temporelles et IDs (pour 2057 lignes)\n",
        "data['workflow_id'] = [f'W-{i:04d}' for i in range(1, NB_LIGNES + 1)]\n",
        "start_time_base = pd.to_datetime('2025-10-20')\n",
        "# √âtalement temporel\n",
        "data['start_time'] = start_time_base + pd.to_timedelta(np.arange(NB_LIGNES) * 500 + np.random.randint(0, 100, NB_LIGNES), unit='s')\n",
        "\n",
        "# Ajout des autres colonnes\n",
        "data['branch_name'] = np.random.choice(['main', 'develop', 'feature-auth', 'feature-payment', 'hotfix'], size=NB_LIGNES, p=[0.3, 0.3, 0.2, 0.1, 0.1])\n",
        "data['repo_name'] = np.random.choice(['repo-api', 'repo-front', 'repo-mobile'], size=NB_LIGNES, p=[0.5, 0.3, 0.2])\n",
        "data['env_type'] = np.random.choice(['prod', 'staging', 'dev'], size=NB_LIGNES, p=[0.2, 0.3, 0.5])\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# TITRE : Calcul de la dur√©e r√©elle et simulation de la pr√©diction du mod√®le ML.\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Dur√©e r√©elle (proportionnelle aux lignes de code + bruit)\n",
        "data['duration_s'] = (data['code_lines_changed'] * 0.8) + np.random.randint(60, 180, size=NB_LIGNES)\n",
        "data['duration_s'] = data['duration_s'].astype(int)\n",
        "\n",
        "# Pr√©diction de Dur√©e\n",
        "data['pred_duration_s'] = data['duration_s'] * np.random.uniform(0.95, 1.05, size=NB_LIGNES)\n",
        "data['pred_duration_s'] = data['pred_duration_s'].astype(int)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# TITRE : Sauvegarde finale des donn√©es pr√©par√©es au format CSV pour l'import dans Grafana.\n",
        "# --------------------------------------------------------------------------------------\n",
        "nom_fichier = 'ci_cd_prediction_mock_2057_errors.csv'\n",
        "data = data[['workflow_id', 'start_time', 'duration_s', 'status', 'pred_duration_s', 'pred_risk_fail', 'branch_name', 'repo_name', 'code_lines_changed', 'env_type', 'error_tag']]\n",
        "data.to_csv(nom_fichier, index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "print(f\"‚úÖ Fichier '{nom_fichier}' de {NB_LIGNES} lignes g√©n√©r√© avec 357 √©checs garantis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TITRE : Bilan de Sant√© Initial du Jeu de Donn√©es\n",
        "Ce bloc charge le fichier CSV et v√©rifie que les types de donn√©es sont corrects pour l'analyse et le Machine Learning."
      ],
      "metadata": {
        "id": "qw35XP05g-xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Charger le jeu de donn√©es (2057 lignes)\n",
        "df = pd.read_csv('ci_cd_prediction_mock_2057_errors.csv')\n",
        "\n",
        "# Convertir la colonne start_time au format datetime\n",
        "df['start_time'] = pd.to_datetime(df['start_time'])\n",
        "\n",
        "print(\"--- Bilan de Sant√© des Donn√©es (2057 lignes) ---\")\n",
        "print(f\"Nombre total de lignes : {len(df)}\")\n",
        "print(f\"Aper√ßu des types de donn√©es :\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "u1Do3kgp4q05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proportion Succ√®s/√âchec (Validation du D√©s√©quilibre)\n",
        "Ce bloc calcule et visualise le taux de d√©s√©quilibre de la variable cible (status )pr√®s l'ajout des 57 erreurs."
      ],
      "metadata": {
        "id": "4rTiHgPllDHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagramme : Analyse du D√©s√©quilibre Succ√®s/√âchec\n",
        "status_counts = df['status'].value_counts()\n",
        "status_percentages = df['status'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"\\n--- Fr√©quence des Statuts de Pipeline ---\")\n",
        "print(status_counts)\n",
        "print(\"\\n--- Pourcentage ---\")\n",
        "print(status_percentages)\n",
        "\n",
        "# Visualisation des pourcentages (Camembert)\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(\n",
        "    status_counts,\n",
        "    labels=status_counts.index,\n",
        "    # Afficher le pourcentage avec une d√©cimale\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=['#4CAF50', '#FF5722']\n",
        ")\n",
        "plt.title('Proportion Succ√®s vs √âchec (Validation du D√©s√©quilibre)')\n",
        "plt.show()\n",
        "#"
      ],
      "metadata": {
        "id": "5sm9TJek4wMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importation de ydata-profilingest la premi√®re √©tape pour  analyse exploratoire"
      ],
      "metadata": {
        "id": "Kf6orBZum9zU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6519a000"
      },
      "source": [
        "import sys\n",
        "\n",
        "# Installer la biblioth√®que ydata-profiling\n",
        "!{sys.executable} -m pip install ydata-profiling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G√©n√©ration du Rapport de Profilage Interactif (Contr√¥le Qualit√© IA)\n",
        "Ce bloc importe la librairie YData-Profiling pour cr√©er un rapport HTML complet du jeu de donn√©es ( df). Ce rapport est utilis√© pour l' analyse exploratoire (EDA) , le contr√¥le de la qualit√©, la d√©tection des valeurs manquantes et l'identification des corr√©lations, garantissant la fiabilit√© des donn√©es avant l'entra√Ænement du mod√®le de Machine Learning."
      ],
      "metadata": {
        "id": "xsPPh-7Xo2R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# G√©n√©rer le rapport de profilage\n",
        "profile = ProfileReport(df, title=\"Rapport de Profilage des Donn√©es CI/CD\", html={\n",
        "    'style': {'full_width': True},\n",
        "    'minify': True,\n",
        "    'inline': True,\n",
        "    'use_local_assets': True\n",
        "}, explorative=True, lazy=False)\n",
        "\n",
        "# Sauvegarder le rapport dans un fichier HTML\n",
        "output_file = \"ci_cd_data_profiling_report_fr.html\"\n",
        "profile.to_file(output_file)\n",
        "\n",
        "# Afficher le rapport directement dans le notebook\n",
        "profile.to_notebook_iframe()\n",
        "\n",
        "print(f\"‚úÖ Rapport de profilage g√©n√©r√© et sauvegard√© sous : '{output_file}'\")"
      ],
      "metadata": {
        "id": "ylno9JZU2IiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entra√Ænement et √âvaluation du Mod√®le For√™t Al√©atoire üå≥"
      ],
      "metadata": {
        "id": "Qk6VFxb9p78S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Initialisation des Modules de Machine Learning et de Mesure\n",
        "Ce bloc importe les outils n√©cessaires √† la mod√©lisation et √† l'√©valuation, y compris les mod√®les de R√©gression Lin√©aire et For√™t Al√©atoire, ainsi que les m√©triques d'erreur (MAE, R2)."
      ],
      "metadata": {
        "id": "Z1nK3girp_Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EAjg5MYaqNFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Pr√©paration des Donn√©es et Encodage des Variables Cat√©gorielles\n",
        "Ce bloc pr√©pare le jeu de donn√©es (df ) en :\n",
        "\n",
        "Excluant les colonnes non pr√©dictives ou cibles ( workflow_id, pred_duration_s, start_time).\n",
        "\n",
        "Encodant les variables textuelles ( branch_name, repo_name, etc.) en colonnes num√©riques binaires (One-Hot Encoding), car les mod√®les ML ne peuvent traiter que des nombres."
      ],
      "metadata": {
        "id": "yFHH04kxqRzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©finition des variables cibles (y) et des variables explicatives (X)\n",
        "colonnes_a_exclure = ['workflow_id', 'pred_duration_s', 'pred_risk_fail', 'start_time']\n",
        "X = df.drop(columns=['duration_s'] + colonnes_a_exclure)\n",
        "y = df['duration_s']\n",
        "\n",
        "# Encodage des Variables Cat√©gorielles\n",
        "colonnes_categoriques = ['status', 'branch_name', 'repo_name', 'env_type', 'error_tag']\n",
        "X_encoded = pd.get_dummies(X, columns=colonnes_categoriques, drop_first=True)"
      ],
      "metadata": {
        "id": "VGju0gbMqpBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "S√©paration du Jeu de Donn√©es (Train/Test Split) et Entra√Ænement du Mod√®le For√™t Al√©atoire\n",
        "Ce bloc divise les donn√©es encod√©es en deux parties (80% pour l'entra√Ænement et 20% pour le test) et entra√Æne le mod√®le Random Forest Regressor , qui utilise une collection d'arbres de d√©cision pour pr√©dire la dur√©e."
      ],
      "metadata": {
        "id": "XKQ22lpBqxhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# S√©paration en ensembles d'entra√Ænement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42\n",
        ")\n",
        "# Entra√Ænement du mod√®le\n",
        "model_rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VNVtcz9YrLO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "√âvaluation de la Performance du Mod√®le de R√©gression\n",
        "Ce bloc utilise les donn√©es de test (que le mod√®le n'a jamais vues) pour v√©rifier sa pr√©cision en calculant deux m√©triques cl√©s :\n",
        "\n",
        "MAE (Erreur Absolue Moyenne) : L'erreur moyenne de la pr√©diction, exprim√©e en secondes.\n",
        "\n",
        "R¬≤ (Coefficient R-carr√©) : La qualit√© de l'ajustement (plus la valeur est proche de 1.0000, mieux c'est)."
      ],
      "metadata": {
        "id": "jlaVf7WErFL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# √âvaluation (pour confirmer la performance)\n",
        "y_pred_rf = model_rf.predict(X_test)\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\n--- Nouvelle Performance For√™t Al√©atoire ---\")\n",
        "print(f\"Erreur Absolue Moyenne (MAE): {mae_rf:.2f}\")\n",
        "print(f\"Coefficient R-carr√© (R2): {r2_rf:.4f}\")"
      ],
      "metadata": {
        "id": "yy-EBWA6rhZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mod√®le de R√©gression Lin√©aire"
      ],
      "metadata": {
        "id": "9aDOFvDIuU7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisation et Entra√Ænement du Mod√®le de R√©gression Lin√©aire\n",
        "Ce bloc importe la classe LinearRegressionet lance le processus d'apprentissage. Le mod√®le est entra√Æn√© sur l'ensemble X_train(caract√©ristiques encod√©es) pour pr√©dire la cible variable y_train(dur√©e r√©elle en secondes)"
      ],
      "metadata": {
        "id": "mSNZSXfbuFTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Initialisation et entra√Ænement du mod√®le Lin√©aire\n",
        "model_linear = LinearRegression()\n",
        "model_linear.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JSbLI_HwumcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pr√©diction et √âvaluation de la Performance (Baseline)\n",
        "Ce bloc utilise le mod√®le entra√Æn√© pour pr√©dire la dur√©e sur les donn√©es de test ( X_test) que le mod√®le n'a jamais vues, puis calculer les m√©triques pour √©valuer sa pr√©cision."
      ],
      "metadata": {
        "id": "5ScY8RZPusmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Pr√©diction sur l'ensemble de test\n",
        "y_pred_linear = model_linear.predict(X_test)\n",
        "\n",
        "# 3. √âvaluation de la performance\n",
        "mae = mean_absolute_error(y_test, y_pred_linear)\n",
        "r2 = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "print(\"\\n--- Performance du Mod√®le de R√©gression Lin√©aire (Baseline) ---\")\n",
        "print(f\"Erreur Absolue Moyenne (MAE): {mae:.2f}\")\n",
        "print(f\"Coefficient R-carr√© (R2): {r2:.4f}\")"
      ],
      "metadata": {
        "id": "BWwEkExqusM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TITRE : Extraction et Interpr√©tation des Coefficients d'Influence\n",
        "Ce bloc de code importe la librairie Pandas pour structurer les r√©sultats. Il extrait les coefficients ($\\beta$) calcul√©s par la R√©gression Lin√©aire ( model_linear.coef_) et les associ√©s aux noms des colonnes encod√©es ( X_train.columns). Il trie les r√©sultats pour identifier les 10 facteurs qui ont le plus grand impact direct (positif ou n√©gatif) sur la dur√©e du pipeline."
      ],
      "metadata": {
        "id": "905Blnadv8E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cr√©er un DataFrame pour les coefficients\n",
        "coefficients = pd.Series(\n",
        "    model_linear.coef_,\n",
        "    index=X_train.columns\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "print(\"\\n--- Top 10 des Coefficients d'Influence (R√©gression Lin√©aire) ---\")\n",
        "print(coefficients.head(10))"
      ],
      "metadata": {
        "id": "6EzUcRw6HY7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TITRE : Sauvegarde et S√©rialisation du Mod√®le Final (Persistance MLOps)\n",
        "Ce bloc de code utilise la librairie joblibpour enregistrer l'objet Python entra√Æn√© ( model_linear) sur le disque local dans un format binaire ( .joblib). Cette √©tape est fondamentale car elle permet de conserver l'√©tat math√©matique du mod√®le (les coefficients calcul√©s) apr√®s la fermeture du Notebook, et de le rendre portable pour un futur d√©ploiement (par exemple, sur Amazon SageMaker)."
      ],
      "metadata": {
        "id": "F-Gywo8PwOd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# 1. D√©finir le nom du fichier de sauvegarde\n",
        "model_filename = 'linear_regression_final_model.joblib'\n",
        "\n",
        "# 2. Sauvegarder l'objet Python 'model_linear' sur le disque\n",
        "# Le mod√®le entra√Æn√© est maintenant un fichier binaire\n",
        "joblib.dump(model_linear, model_filename)\n",
        "\n",
        "print(f\"‚úÖ Mod√®le sauvegard√© avec succ√®s sous : '{model_filename}'\")"
      ],
      "metadata": {
        "id": "lcN3av_-aQE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pr√©diction de la Dur√©e d'un Nouveau Pipeline (Inf√©rence ML)\n",
        "Ce bloc de code ex√©cute l'inf√©rence (la pr√©diction) en temps r√©el en utilisant le mod√®le de R√©gression Lin√©aire sauvegard√©. Le processus garantit que la nouvelle donn√©e de pipeline est encod√©e et align√©e (One-Hot Encoding, m√™me ordre de colonnes) pour correspondre parfaitement au format attendu par le mod√®le adopt√©, simulant ainsi un appel API vers un point final SageMaker."
      ],
      "metadata": {
        "id": "1KRvNULixWNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Charger le mod√®le sauvegard√©\n",
        "model_loaded = joblib.load('linear_regression_final_model.joblib')\n",
        "\n",
        "# R√©cup√©rer les colonnes de X_train pour s'assurer de l'ordre et des colonnes pr√©sentes\n",
        "feature_columns = X_train.columns\n",
        "\n",
        "# D√©finir les variables cat√©gorielles (doit correspondre √† la liste utilis√©e pour l'entra√Ænement)\n",
        "colonnes_categoriques = ['status', 'branch_name', 'repo_name', 'env_type', 'error_tag']\n",
        "\n",
        "# --- Pr√©paration de la nouvelle donn√©e pour la pr√©diction ---\n",
        "\n",
        "# 2. Cr√©er un DataFrame pour le nouveau point de donn√©e avec les colonnes originales\n",
        "new_observation_raw = pd.DataFrame({\n",
        "    'code_lines_changed': [500],\n",
        "    'status': ['success'], # Valeur r√©elle pour 'status'\n",
        "    'branch_name': ['develop'], # Valeur r√©elle pour 'branch_name'\n",
        "    'repo_name': ['repo-api'], # Valeur r√©elle pour 'repo-api'\n",
        "    'env_type': ['dev'], # Valeur r√©elle pour 'env_type'\n",
        "    'error_tag': ['None'] # Valeur r√©elle pour 'error_tag'\n",
        "})\n",
        "\n",
        "# 3. Appliquer le One-Hot Encoding au nouveau point de donn√©e, avec drop_first=True\n",
        "new_observation_encoded = pd.get_dummies(new_observation_raw, columns=colonnes_categoriques, drop_first=True)\n",
        "\n",
        "# 4. Aligner les colonnes du nouveau point de donn√©e encod√© avec les colonnes utilis√©es pour l'entra√Ænement (X_train)\n",
        "# Les colonnes manquantes seront remplies avec 0, et les colonnes suppl√©mentaires (si elles apparaissent en raison de get_dummies)\n",
        "# qui n'√©taient pas dans X_train seront supprim√©es.\n",
        "new_data_point = new_observation_encoded.reindex(columns=feature_columns, fill_value=0)\n",
        "\n",
        "# Assurez-vous que toutes les colonnes num√©riques sont du bon type pour correspondre √† X_train\n",
        "for col in feature_columns:\n",
        "    if col in new_data_point.columns:\n",
        "        new_data_point[col] = new_data_point[col].astype(X_train[col].dtype)\n",
        "\n",
        "# 5. Ex√©cuter la pr√©diction sur la nouvelle ligne de donn√©es\n",
        "predicted_duration = model_loaded.predict(new_data_point)\n",
        "\n",
        "# 6. Afficher le r√©sultat\n",
        "print(\"\\n--- R√©sultat de la Pr√©diction ---\")\n",
        "print(f\"Dur√©e pr√©dite du pipeline avec 500 lignes de changement : {predicted_duration[0]:.2f} secondes\")\n",
        "print(f\"Soit environ {predicted_duration[0] / 60:.2f} minutes.\")"
      ],
      "metadata": {
        "id": "0YbLNIzRcws0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}